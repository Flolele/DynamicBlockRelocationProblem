{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import ticker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockRelocationAnalyzer:\n",
    "    def __init__(self, results_path: str):\n",
    "        with open(results_path, 'r') as f:\n",
    "            self.raw_data = json.load(f)\n",
    "            \n",
    "            self.warehouse_info = self.raw_data['warehouse']\n",
    "            \n",
    "        self.warehouse_str = f\"Warehouse {self.warehouse_info['dimensions']}\"\n",
    "        self.snapshots_df = self._process_snapshots()\n",
    "        self.runs_df = self._process_runs()\n",
    "            \n",
    "        # Set better plotting style\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        plt.rcParams.update({\n",
    "            'font.family': 'serif',\n",
    "            'font.size': 10,\n",
    "            'figure.figsize': [20, 20],\n",
    "            'axes.titlesize': 11,\n",
    "            'axes.labelsize': 10,\n",
    "            'legend.fontsize': 9,\n",
    "            'legend.framealpha': 1.0,\n",
    "            'legend.facecolor': 'white',\n",
    "            'legend.edgecolor': 'gray'\n",
    "        })\n",
    "\n",
    "    def _process_snapshots(self) -> pd.DataFrame:\n",
    "        records = []\n",
    "        # Create event type mapping\n",
    "        event_type_map = {\n",
    "            0: 'ExpectedExecutionEvent',\n",
    "            1: 'NewBlockEvent',\n",
    "            2: 'MissmoveEvent',\n",
    "            3: 'BlockTargetUpdateEvent'\n",
    "        }\n",
    "        \n",
    "        for run in self.raw_data['runs']:\n",
    "            seed = run['seed']\n",
    "            for config_id, result in run['results'].items():\n",
    "                variant = next(c['variant'] for c in self.raw_data['configs'] \n",
    "                            if c['id'] == config_id)\n",
    "                \n",
    "                for snapshot in result['snapshots']:\n",
    "                    record = {\n",
    "                        'seed': seed,\n",
    "                        'variant': variant,\n",
    "                        'event_number': snapshot['eventNumber'],\n",
    "                        'total_cost_so_far': snapshot.get('totalCostSoFar', 0),\n",
    "                        'recalculation_time': snapshot.get('recalculationTimeMs'),\n",
    "                        'event_type': event_type_map[snapshot['eventType']],  # Map the numeric event type to string\n",
    "                        'warehouse_utilization': snapshot['warehouseUtilization'],\n",
    "                        'arrival_queue_size': snapshot['arrivalStackHeight'],\n",
    "                        'blocked_blocks': snapshot['blockedBlocks'],\n",
    "                        'empty_stacks': snapshot['emptyStacks'],\n",
    "                        'planned_moves': snapshot['plannedMovesRemaining'],\n",
    "                        'bound_change': snapshot.get('boundChange', 0)  # Get bound change directly from snapshot\n",
    "                    }\n",
    "                    records.append(record)\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "    def _process_runs(self) -> pd.DataFrame:\n",
    "        records = []\n",
    "        for run in self.raw_data['runs']:\n",
    "            seed = run['seed']\n",
    "            for config_id, result in run['results'].items():\n",
    "                variant = next(c['variant'] for c in self.raw_data['configs'] \n",
    "                            if c['id'] == config_id)\n",
    "                # Get total events configured from configs\n",
    "                total_events = next(c['totalEvents'] for c in self.raw_data['configs'] \n",
    "                                if c['id'] == config_id)\n",
    "                \n",
    "                # Calculate events reached percentage\n",
    "                events_reached = sum(result['eventCounts'].values())\n",
    "                events_reached_percentage = (events_reached / total_events) * 100\n",
    "                \n",
    "                record = {\n",
    "                    'seed': seed,\n",
    "                    'variant': variant,\n",
    "                    'runtime': result['runtime'],\n",
    "                    'total_cost': result['totalMoveCost'],\n",
    "                    'total_moves': result['totalMovesExecuted'],\n",
    "                    'averageRecalculationTime': result['averageRecalculationTime'],\n",
    "                    'totalRecalculationTime': result['totalRecalculationTime'],\n",
    "                    'totalMovesExecuted': result['totalMovesExecuted'],\n",
    "                    'totalMoveCost': result['totalMoveCost'],\n",
    "                    'recalculationCount': result['recalculationCount'],\n",
    "                    'status': result['status'],\n",
    "                    'events_reached': events_reached,\n",
    "                    'events_reached_percentage': events_reached_percentage,\n",
    "                    'total_events_configured': total_events\n",
    "                }\n",
    "                records.append(record)\n",
    "        return pd.DataFrame(records)\n",
    "    \n",
    "    def generate_summary_stats(self, output_path: Path):\n",
    "        \"\"\"Generate and save summary statistics as CSV\"\"\"\n",
    "        summary = self.runs_df.groupby('variant').agg({\n",
    "            'runtime': ['mean', 'std', 'min', 'max'],\n",
    "            'total_cost': ['mean', 'std', 'min', 'max'],\n",
    "            'events_reached_percentage': ['mean', 'std', 'min', 'max'],\n",
    "            'total_moves': ['mean', 'std', 'min', 'max']\n",
    "        }).round(2)\n",
    "        \n",
    "        # Add status distribution\n",
    "        status_dist = pd.crosstab(\n",
    "            self.runs_df['variant'], \n",
    "            self.runs_df['status'], \n",
    "            normalize='index'\n",
    "        ).round(3) * 100\n",
    "        \n",
    "        # Combine statistics\n",
    "        for status in status_dist.columns:\n",
    "            summary[('status_distribution', status)] = status_dist[status]\n",
    "        \n",
    "        # Save to CSV\n",
    "        summary.to_csv(output_path / 'summary_statistics.csv')\n",
    "        return summary\n",
    "\n",
    "    def _format_variant_name(self, name: str) -> str:\n",
    "        \"\"\"Format variant names for better readability\"\"\"\n",
    "        words = []\n",
    "        current = \"\"\n",
    "        for char in name:\n",
    "            if char.isupper() and current:\n",
    "                words.append(current)\n",
    "                current = char\n",
    "            else:\n",
    "                current += char\n",
    "        words.append(current)\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def plot_analysis(self, save_path = None):\n",
    "        \"\"\"Generate comprehensive analysis plots\"\"\"\n",
    "        fig = plt.figure(figsize=(30, 30))\n",
    "        # Increase spacing between plots\n",
    "        gs = plt.GridSpec(5, 2, figure=fig, hspace=0.5, wspace=0.4)\n",
    "        \n",
    "        # Get variants in original order from the config\n",
    "        variants = [config['variant'] for config in self.raw_data['configs']]\n",
    "        \n",
    "        # Set up consistent colors and markers for variants\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, len(variants)))\n",
    "        markers = ['o', 's', '^', 'D', 'v', 'p', '*']\n",
    "        variant_styles = {\n",
    "            variant: {\n",
    "                'color': color,\n",
    "                'marker': marker\n",
    "            }\n",
    "            for variant, color, marker in zip(variants, colors, markers)\n",
    "        }\n",
    "        \n",
    "        # 1. Total Cost vs Runtime\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        for variant in variants:\n",
    "            variant_data = self.runs_df[self.runs_df['variant'] == variant]\n",
    "            style = variant_styles[variant]\n",
    "            \n",
    "            # Get successful runs only for plotting\n",
    "            successful_data = variant_data[variant_data['status'] == 'Completed']\n",
    "            if len(successful_data) > 0:\n",
    "                ax1.scatter(\n",
    "                    successful_data['runtime'],\n",
    "                    successful_data['total_cost'],\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    s=100,\n",
    "                    alpha=0.7\n",
    "                )\n",
    "\n",
    "            # Check for failed runs and add to legend if present\n",
    "            failed_runs = variant_data[variant_data['status'] == 'Failed']\n",
    "            if len(failed_runs) > 0:\n",
    "                label = f\"{self._format_variant_name(variant)} (Failed)\"\n",
    "            else:\n",
    "                label = self._format_variant_name(variant)\n",
    "\n",
    "            # terminated runs\n",
    "            terminated_runs = variant_data[variant_data['status'] == 'Terminated']\n",
    "            if len(terminated_runs) > 0:\n",
    "                label = f\"{self._format_variant_name(variant)} (Terminated)\"\n",
    "            else:\n",
    "                label = self._format_variant_name(variant)\n",
    "                \n",
    "            # Add legend entry\n",
    "            ax1.scatter([], [], # Empty scatter for legend\n",
    "                label=label,\n",
    "                color=style['color'],\n",
    "                marker=style['marker'],\n",
    "                s=100,\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "        ax1.set_title('Total Cost vs Runtime (by Status)')\n",
    "        ax1.set_xlabel('Runtime (seconds)')\n",
    "        ax1.set_ylabel('Total Cost')\n",
    "        ax1.legend(bbox_to_anchor=(1.02, 1), fontsize=8, labelspacing=0.2)\n",
    "        \n",
    "        # 2. Cost Accumulation\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        completed_snapshots = self.snapshots_df[\n",
    "            self.snapshots_df['variant'].isin(\n",
    "                self.runs_df[self.runs_df['status'] == 'Completed']['variant']\n",
    "            )\n",
    "        ]\n",
    "        cost_by_event = completed_snapshots.groupby(['variant', 'event_number'])['total_cost_so_far'].mean().reset_index()\n",
    "        \n",
    "        for variant in variants:\n",
    "            variant_data = cost_by_event[cost_by_event['variant'] == variant]\n",
    "            if len(variant_data) > 0:  # Only plot if there's data\n",
    "                style = variant_styles[variant]\n",
    "                ax2.plot(\n",
    "                    variant_data['event_number'],\n",
    "                    variant_data['total_cost_so_far'],\n",
    "                    label=f\"{self._format_variant_name(variant)} (n={len(self.runs_df[(self.runs_df['variant'] == variant) & (self.runs_df['status'] == 'Completed')])})\",\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markevery=20,\n",
    "                    markersize=6,\n",
    "                    linewidth=2\n",
    "                )\n",
    "        ax2.set_title('Cost Accumulation Over Time (Completed Runs Only)')\n",
    "        ax2.set_xlabel('Event Number')\n",
    "        ax2.set_ylabel('Total Cost')\n",
    "        ax2.legend(bbox_to_anchor=(1.02, 1), fontsize=8, labelspacing=0.2)\n",
    "        \n",
    "        # 3. Arrival Queue Size\n",
    "        ax3 = fig.add_subplot(gs[1, 0])\n",
    "        queue_by_event = self.snapshots_df.groupby(['variant', 'event_number'])['arrival_queue_size'].mean().reset_index()\n",
    "        for variant in variants:\n",
    "            variant_data = queue_by_event[queue_by_event['variant'] == variant]\n",
    "            style = variant_styles[variant]\n",
    "            ax3.plot(\n",
    "                variant_data['event_number'],\n",
    "                variant_data['arrival_queue_size'],\n",
    "                label=self._format_variant_name(variant),\n",
    "                color=style['color'],\n",
    "                marker=style['marker'],\n",
    "                markevery=20,\n",
    "                markersize=6,\n",
    "                linewidth=2\n",
    "            )\n",
    "        # Add horizontal line for allowed queue size\n",
    "        allowed_queue_size = 3 \n",
    "        ax3.axhline(y=allowed_queue_size, color='red', linestyle='--', linewidth=1.5, label='Allowed Size')\n",
    "        \n",
    "        ax3.set_title('Arrival Queue Size Evolution')\n",
    "        ax3.set_xlabel('Event Number')\n",
    "        ax3.set_ylabel('Queue Size')\n",
    "        ax3.legend(bbox_to_anchor=(1.02, 1), fontsize=8, labelspacing=0.2)\n",
    "        \n",
    "        # 4. Empty Stacks\n",
    "        ax4 = fig.add_subplot(gs[1, 1])\n",
    "        empty_by_event = self.snapshots_df.groupby(['variant', 'event_number'])['empty_stacks'].mean().reset_index()\n",
    "        for variant in variants:\n",
    "            variant_data = empty_by_event[empty_by_event['variant'] == variant]\n",
    "            style = variant_styles[variant]\n",
    "            ax4.plot(\n",
    "                variant_data['event_number'],\n",
    "                variant_data['empty_stacks'],\n",
    "                label=self._format_variant_name(variant),\n",
    "                color=style['color'],\n",
    "                marker=style['marker'],\n",
    "                markevery=20,\n",
    "                markersize=6,\n",
    "                linewidth=2\n",
    "            )\n",
    "        ax4.set_title('Empty Stacks Evolution')\n",
    "        ax4.set_xlabel('Event Number')\n",
    "        ax4.set_ylabel('Number of Empty Stacks')\n",
    "        ax4.legend(bbox_to_anchor=(1.02, 1), fontsize=8, labelspacing=0.2)\n",
    "        \n",
    "        # 5. Event Distribution\n",
    "        ax5 = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "        # Define the desired column order\n",
    "        desired_order = ['ExpectedExecutionEvent', 'NewBlockEvent', 'MissmoveEvent', 'BlockTargetUpdateEvent']\n",
    "\n",
    "        event_counts = pd.crosstab(\n",
    "            pd.Categorical(self.snapshots_df['variant'], categories=variants),\n",
    "            self.snapshots_df['event_type'],\n",
    "            normalize='index'\n",
    "        ) * 100\n",
    "\n",
    "        # Reorder the columns\n",
    "        event_counts = event_counts[desired_order]\n",
    "\n",
    "        event_colors = plt.cm.Set3(np.linspace(0, 1, 4))\n",
    "        event_counts.plot(\n",
    "            kind='bar',\n",
    "            stacked=True,\n",
    "            ax=ax5,\n",
    "            width=0.8,\n",
    "            color=event_colors\n",
    "        )\n",
    "\n",
    "        ax5.set_title('Event Type Distribution')\n",
    "        ax5.set_xlabel('Variant')\n",
    "        ax5.set_ylabel('Proportion (%)')\n",
    "        ax5.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax5.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # Legend order will now match the stacking order\n",
    "        ax5.legend(\n",
    "            ['Expected Execution', 'New Block', 'Missmove', 'Block Target Update'],\n",
    "            title='Event Type',\n",
    "            bbox_to_anchor=(1.02, 1),\n",
    "            fontsize=8,\n",
    "            labelspacing=0.2\n",
    "        )\n",
    "        \n",
    "        # 6. Recalculation Times\n",
    "        ax6 = fig.add_subplot(gs[2, 1])\n",
    "        recalc_data = self.snapshots_df[self.snapshots_df['recalculation_time'].notna()].copy()\n",
    "        recalc_data['variant'] = pd.Categorical(recalc_data['variant'], categories=variants)\n",
    "        palette = {variant: style['color'] for variant, style in variant_styles.items()}\n",
    "        sns.boxplot(\n",
    "            data=recalc_data,\n",
    "            x='variant',\n",
    "            y='recalculation_time',\n",
    "            ax=ax6,\n",
    "            palette=palette,\n",
    "            showfliers=False,\n",
    "            order=variants\n",
    "        )\n",
    "        ax6.set_title('Recalculation Time Distribution')\n",
    "        ax6.set_xlabel('Variant')\n",
    "        ax6.set_ylabel('Recalculation Time (ms)')\n",
    "        ax6.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax6.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "        \n",
    "        # 7. Planned Moves Evolution\n",
    "        ax7 = fig.add_subplot(gs[3, 0])\n",
    "        moves_by_event = self.snapshots_df.groupby(['variant', 'event_number'])['planned_moves'].mean().reset_index()\n",
    "        for variant in variants:\n",
    "            variant_data = moves_by_event[moves_by_event['variant'] == variant]\n",
    "            style = variant_styles[variant]\n",
    "            ax7.plot(\n",
    "                variant_data['event_number'],\n",
    "                variant_data['planned_moves'],\n",
    "                label=self._format_variant_name(variant),\n",
    "                color=style['color'],\n",
    "                marker=style['marker'],\n",
    "                markevery=20,\n",
    "                markersize=6,\n",
    "                linewidth=2\n",
    "            )\n",
    "        ax7.set_title('Planned Moves Evolution')\n",
    "        ax7.set_xlabel('Event Number')\n",
    "        ax7.set_ylabel('Number of Planned Moves')\n",
    "        ax7.legend(bbox_to_anchor=(1.02, 1), fontsize=8, labelspacing=0.2)\n",
    "        \n",
    "        # 8. Warehouse Utilization\n",
    "        ax8 = fig.add_subplot(gs[3, 1])\n",
    "        util_by_event = self.snapshots_df.groupby(['variant', 'event_number'])['warehouse_utilization'].mean().reset_index()\n",
    "        for variant in variants:\n",
    "            variant_data = util_by_event[util_by_event['variant'] == variant]\n",
    "            style = variant_styles[variant]\n",
    "            ax8.plot(\n",
    "                variant_data['event_number'],\n",
    "                variant_data['warehouse_utilization'] * 100,\n",
    "                label=self._format_variant_name(variant),\n",
    "                color=style['color'],\n",
    "                marker=style['marker'],\n",
    "                markevery=20,\n",
    "                markersize=6,\n",
    "                linewidth=2\n",
    "            )\n",
    "        ax8.set_title('Warehouse Utilization Over Time')\n",
    "        ax8.set_xlabel('Event Number')\n",
    "        ax8.set_ylabel('Utilization (%)')\n",
    "        ax8.legend(bbox_to_anchor=(1.02, 1), fontsize=8, labelspacing=0.2)\n",
    "\n",
    "        ax9 = fig.add_subplot(gs[4, 1])  \n",
    "        status_counts = pd.crosstab(\n",
    "            pd.Categorical(self.runs_df['variant'], categories=variants),\n",
    "            self.runs_df['status'],\n",
    "            normalize='index'\n",
    "        ) * 100\n",
    "        status_colors = {'Completed': '#2ecc71', 'Failed': '#e74c3c', 'Terminated': '#f1c40f'}\n",
    "        status_counts.plot(\n",
    "            kind='bar',\n",
    "            stacked=True,\n",
    "            ax=ax9,\n",
    "            color=[status_colors.get(x, '#95a5a6') for x in status_counts.columns],\n",
    "            width=0.8\n",
    "        )\n",
    "        ax9.set_title('Simulation Status Distribution')\n",
    "        ax9.set_xlabel('Variant')\n",
    "        ax9.set_ylabel('Proportion (%)')\n",
    "        ax9.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax9.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "        ax9.legend(title='Status', bbox_to_anchor=(1.02, 1), fontsize=8, labelspacing=0.2)\n",
    "\n",
    "\n",
    "        # Get just the colors from variant_styles\n",
    "        variant_colors = {variant: style['color'] for variant, style in variant_styles.items()}\n",
    "\n",
    "        # Add new subplot for events reached\n",
    "        ax_events = fig.add_subplot(gs[4, 0])  # Adjust grid as needed\n",
    "\n",
    "        # Create boxplot for events reached percentage using just the colors\n",
    "        sns.boxplot(\n",
    "            data=self.runs_df,\n",
    "            x='variant',\n",
    "            y='events_reached_percentage',\n",
    "            ax=ax_events,\n",
    "            palette=variant_colors,  # Use the color dictionary instead\n",
    "            showfliers=False\n",
    "        )\n",
    "\n",
    "        # Add individual points\n",
    "        sns.stripplot(\n",
    "            data=self.runs_df,\n",
    "            x='variant',\n",
    "            y='events_reached_percentage',\n",
    "            ax=ax_events,\n",
    "            color='black',\n",
    "            alpha=0.4,\n",
    "            size=4,\n",
    "            jitter=0.2\n",
    "        )\n",
    "\n",
    "        ax_events.set_title('Percentage of Events Reached by Variant')\n",
    "        ax_events.set_xlabel('Variant')\n",
    "        ax_events.set_ylabel('Events Reached (%)')\n",
    "        ax_events.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax_events.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Adjust layout to prevent overlap\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])  # Leave more space on the right for legends\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path / 'analysis.png', dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "        event_impact_fig = self.plot_event_impact()\n",
    "        if save_path:\n",
    "            event_impact_fig.savefig(save_path / 'event_impact.png', \n",
    "                                    dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "            plt.close(event_impact_fig)\n",
    "\n",
    "    def plot_event_impact(self):\n",
    "        \"\"\"Create visualization showing bound impact per event type\"\"\"\n",
    "        # Create figure with two subplots side by side\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        \n",
    "        variants = [config['variant'] for config in self.raw_data['configs']]\n",
    "        event_types = ['NewBlockEvent', 'MissmoveEvent', 'BlockTargetUpdateEvent']\n",
    "        \n",
    "        # Calculate average bound change per event type for each variant\n",
    "        impact_data = []\n",
    "        for variant in variants:\n",
    "            variant_snapshots = self.snapshots_df[self.snapshots_df['variant'] == variant]\n",
    "            \n",
    "            for event_type in event_types:\n",
    "                avg_impact = variant_snapshots[\n",
    "                    variant_snapshots['event_type'] == event_type\n",
    "                ]['bound_change'].median()\n",
    "                \n",
    "                impact_data.append({\n",
    "                    'variant': variant,\n",
    "                    'event_type': event_type,\n",
    "                    'avg_impact': avg_impact if not pd.isna(avg_impact) else 0\n",
    "                })\n",
    "        \n",
    "        # Convert to DataFrame for easier plotting\n",
    "        impact_df = pd.DataFrame(impact_data)\n",
    "        \n",
    "        # BAR PLOT\n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(variants))\n",
    "        width = 0.25  # Slightly wider bars since we have one less event type\n",
    "        multiplier = 0\n",
    "        \n",
    "        # Plot bars for each event type\n",
    "        for event_type in event_types:\n",
    "            event_data = impact_df[impact_df['event_type'] == event_type]\n",
    "            offset = width * multiplier\n",
    "            rects = ax1.bar(x + offset, event_data['avg_impact'], width,\n",
    "                        label=event_type.replace('Event', ''))\n",
    "            multiplier += 1\n",
    "        \n",
    "        # Customize the bar plot\n",
    "        ax1.set_ylabel('Median Bound Change')\n",
    "        ax1.set_title('Median Bound Change by Event Type and Variant', pad=20, fontsize=12, fontweight='bold')\n",
    "        ax1.set_xticks(x + width)\n",
    "        ax1.set_xticklabels([self._format_variant_name(v) for v in variants],\n",
    "                        rotation=45, ha='right')\n",
    "        ax1.legend(title='Event Type', bbox_to_anchor=(1.02, 1))\n",
    "        ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on the bars\n",
    "        for rect in ax1.patches:\n",
    "            height = rect.get_height()\n",
    "            ax1.annotate(f'{height:.1f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3 if height >= 0 else -3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom' if height >= 0 else 'top',\n",
    "                    fontsize=8)\n",
    "\n",
    "        # BOXPLOT\n",
    "        # Prepare data for boxplot\n",
    "        boxplot_data = []\n",
    "        variant_labels = []\n",
    "        event_labels = []\n",
    "        \n",
    "        for variant in variants:\n",
    "            variant_snapshots = self.snapshots_df[self.snapshots_df['variant'] == variant]\n",
    "            for event_type in event_types:\n",
    "                bound_changes = variant_snapshots[\n",
    "                    variant_snapshots['event_type'] == event_type\n",
    "                ]['bound_change'].values\n",
    "                boxplot_data.append(bound_changes)\n",
    "                variant_labels.extend([self._format_variant_name(variant)] * len(bound_changes))\n",
    "                event_labels.extend([event_type.replace('Event', '')] * len(bound_changes))\n",
    "        \n",
    "        # Create DataFrame for boxplot\n",
    "        boxplot_df = pd.DataFrame({\n",
    "            'Variant': variant_labels,\n",
    "            'Event Type': event_labels,\n",
    "            'Bound Change': np.concatenate(boxplot_data)\n",
    "        })\n",
    "        \n",
    "        # Create boxplot\n",
    "        sns.boxplot(data=boxplot_df, x='Variant', y='Bound Change', hue='Event Type', ax=ax2)\n",
    "        ax2.set_title('Distribution of Bound Changes by Event Type', pad=20, fontsize=12, fontweight='bold')\n",
    "        ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "        ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.suptitle('Analysis of Bound Changes by Event Type and Variant', \n",
    "                    fontsize=14, fontweight='bold', y=1.05)\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "            \n",
    "    def analyze_correlations(self):\n",
    "        \"\"\"Calculate and print correlations between warehouse utilization, planned moves, and arrival queue size\"\"\"\n",
    "        print(\"\\nCorrelation Analysis:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get unique variants\n",
    "        variants = self.snapshots_df['variant'].unique()\n",
    "        \n",
    "        for variant in variants:\n",
    "            variant_data = self.snapshots_df[self.snapshots_df['variant'] == variant]\n",
    "            \n",
    "            # Calculate correlation matrix for the three metrics\n",
    "            correlation_matrix = variant_data[[\n",
    "                'warehouse_utilization',\n",
    "                'planned_moves',\n",
    "                'arrival_queue_size'\n",
    "            ]].corr()\n",
    "            \n",
    "            print(f\"\\nVariant: {self._format_variant_name(variant)}\")\n",
    "            print(\"\\nCorrelation Matrix:\")\n",
    "            print(correlation_matrix.round(3))\n",
    "            print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "    def plot_compact_correlations(self):\n",
    "        \"\"\"Create a single, compact correlation comparison across variants\"\"\"\n",
    "        # Get variants in original order from configs\n",
    "        variants = [config['variant'] for config in self.raw_data['configs']]\n",
    "        \n",
    "        # Create a DataFrame to store all correlations\n",
    "        correlation_data = []\n",
    "        metric_pairs = [\n",
    "            ('warehouse_utilization', 'planned_moves', 'Utilization-Planned Moves'),\n",
    "            ('warehouse_utilization', 'arrival_queue_size', 'Utilization-Arrival Queue'),\n",
    "            ('planned_moves', 'arrival_queue_size', 'Planned Moves-Arrival Queue')\n",
    "        ]\n",
    "        \n",
    "        for variant in variants:\n",
    "            variant_data = self.snapshots_df[self.snapshots_df['variant'] == variant]\n",
    "            corr_matrix = variant_data[[\n",
    "                'warehouse_utilization',\n",
    "                'planned_moves',\n",
    "                'arrival_queue_size'\n",
    "            ]].corr()\n",
    "            \n",
    "            for metric1, metric2, pair_name in metric_pairs:\n",
    "                correlation_data.append({\n",
    "                    'Variant': self._format_variant_name(variant),\n",
    "                    'Metric Pair': pair_name,\n",
    "                    'Correlation': corr_matrix.loc[metric1, metric2]\n",
    "                })\n",
    "        \n",
    "        df_correlations = pd.DataFrame(correlation_data)\n",
    "        \n",
    "        # Create the visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create heatmap\n",
    "        pivot_table = df_correlations.pivot(\n",
    "            index='Metric Pair', \n",
    "            columns='Variant', \n",
    "            values='Correlation'\n",
    "        )\n",
    "        \n",
    "        sns.heatmap(\n",
    "            pivot_table,\n",
    "            annot=True,\n",
    "            fmt='.3f',\n",
    "            cmap='Reds',  # Using Reds colormap but keeping full scale\n",
    "            center=0,\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            cbar_kws={'label': 'Correlation Coefficient'}\n",
    "        )\n",
    "        \n",
    "        plt.title('Correlation Analysis Across Variants', pad=20)\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt.gcf()\n",
    "\n",
    "    def analyze_correlations_compact(self, save_path=None):\n",
    "        \"\"\"Generate and save compact correlation analysis\"\"\"\n",
    "        fig = self.plot_compact_correlations()\n",
    "        \n",
    "        if save_path:\n",
    "            fig.savefig(save_path / 'correlation_analysis_compact.png', \n",
    "                    dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "            plt.close(fig)\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "# Add this to your existing analysis method\n",
    "def analyze_correlations(self, save_path=None):\n",
    "    \"\"\"Calculate correlations and optionally save visualization\"\"\"\n",
    "    # Print numerical results\n",
    "    print(\"\\nCorrelation Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    variants = self.snapshots_df['variant'].unique()\n",
    "    for variant in variants:\n",
    "        variant_data = self.snapshots_df[self.snapshots_df['variant'] == variant]\n",
    "        correlation_matrix = variant_data[[\n",
    "            'warehouse_utilization',\n",
    "            'planned_moves',\n",
    "            'arrival_queue_size'\n",
    "        ]].corr()\n",
    "        \n",
    "        print(f\"\\nVariant: {self._format_variant_name(variant)}\")\n",
    "        print(\"\\nCorrelation Matrix:\")\n",
    "        print(correlation_matrix.round(3))\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "    \n",
    "    # Create and save visualization\n",
    "    fig = self.plot_correlation_heatmap()\n",
    "    if save_path:\n",
    "        fig.savefig(save_path / 'correlation_analysis.png', \n",
    "                   dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "def generate_visualizations(results_path: str, output_dir: str = 'visualization_output'):\n",
    "    analyzer = BlockRelocationAnalyzer(results_path)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    analyzer.plot_analysis(output_path)\n",
    "    analyzer.generate_summary_stats(output_path)\n",
    "    analyzer.analyze_correlations()\n",
    "    analyzer.plot_compact_correlations()\n",
    "\n",
    "    return analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustnessAnalyzer(BlockRelocationAnalyzer):\n",
    "    def __init__(self, results_paths: List[str]):\n",
    "        \"\"\"Initialize with multiple result files from different seeds\"\"\"\n",
    "        # Initialize with first file to get warehouse info and configs\n",
    "        with open(results_paths[0], 'r') as f:\n",
    "            first_data = json.load(f)\n",
    "            self.warehouse_info = first_data['warehouse']\n",
    "            self.raw_data = {\n",
    "                'warehouse': self.warehouse_info,\n",
    "                'configs': first_data['configs'],\n",
    "                'runs': []\n",
    "            }\n",
    "        \n",
    "        # Collect runs from all files\n",
    "        for path in results_paths:\n",
    "            with open(path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                self.raw_data['runs'].extend(data['runs'])\n",
    "        \n",
    "        self.warehouse_str = f\"Warehouse {self.warehouse_info['dimensions']}\"\n",
    "        self.snapshots_df = self._process_snapshots()\n",
    "        self.runs_df = self._process_runs()\n",
    "        \n",
    "        # Initialize plotting style from parent class\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        plt.rcParams.update({\n",
    "            'font.family': 'serif',\n",
    "            'font.size': 10,\n",
    "            'figure.figsize': [20, 20],\n",
    "            'axes.titlesize': 11,\n",
    "            'axes.labelsize': 10,\n",
    "            'legend.fontsize': 9,\n",
    "            'legend.framealpha': 1.0,\n",
    "            'legend.facecolor': 'white',\n",
    "            'legend.edgecolor': 'gray'\n",
    "        })\n",
    "\n",
    "    def plot_robustness_analysis(self, save_path: Path = None):\n",
    "        \"\"\"Create improved robustness analysis visualizations\"\"\"\n",
    "        fig = plt.figure(figsize=(30, 25))\n",
    "        gs = plt.GridSpec(4, 2, figure=fig, hspace=0.5, wspace=0.4)\n",
    "        \n",
    "        # Get variants in original order from config\n",
    "        variants = [config['variant'] for config in self.raw_data['configs']]\n",
    "        \n",
    "        # Set up consistent colors and markers for variants\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, len(variants)))\n",
    "        markers = ['o', 's', '^', 'D', 'v', 'p', '*']\n",
    "        variant_styles = {\n",
    "            variant: {\n",
    "                'color': color,\n",
    "                'marker': marker\n",
    "            }\n",
    "            for variant, color, marker in zip(variants, colors, markers)\n",
    "        }\n",
    "\n",
    "        # 1. Success Rate by Variant with improved colors and order\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        success_rates = self.runs_df.groupby('variant')['status'].value_counts(normalize=True).unstack()\n",
    "        success_rates = success_rates.reindex(variants)\n",
    "        \n",
    "        # Reorder columns to put Terminated in middle and Failed on top\n",
    "        status_colors = {\n",
    "            'Failed': '#e74c3c',  # Red\n",
    "            'Terminated': '#f1c40f',  # Yellow\n",
    "            'Completed': '#2ecc71'  # Green\n",
    "        }\n",
    "        status_order = ['Failed', 'Terminated', 'Completed']\n",
    "        success_rates = success_rates[status_order]\n",
    "        \n",
    "        success_rates.plot(\n",
    "            kind='bar',\n",
    "            stacked=True,\n",
    "            ax=ax1,\n",
    "            color=[status_colors[x] for x in status_order]\n",
    "        )\n",
    "        \n",
    "        # Add percentage labels on bars\n",
    "        for c in ax1.containers:\n",
    "            # Convert to percentages\n",
    "            labels = [f'{(v*100):.0f}%' if v > 0 else '' for v in c.datavalues]\n",
    "            ax1.bar_label(c, labels=labels, label_type='center')\n",
    "            \n",
    "        ax1.set_title('Success Rate by Variant Across All Seeds')\n",
    "        ax1.set_xlabel('Variant')\n",
    "        ax1.set_ylabel('Percentage')\n",
    "        ax1.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax1.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "        ax1.legend(title='Status', bbox_to_anchor=(1.02, 1))\n",
    "\n",
    "        # 2. Total Events Distribution\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        total_events = self.runs_df.groupby(['variant', 'seed'])['events_reached'].mean().reset_index()\n",
    "        # Force the order of variants\n",
    "        total_events['variant'] = pd.Categorical(total_events['variant'], categories=variants, ordered=True)\n",
    "        sns.boxplot(\n",
    "            data=total_events,\n",
    "            x='variant',\n",
    "            y='events_reached',\n",
    "            ax=ax2,\n",
    "            order=variants,\n",
    "            palette={v: style['color'] for v, style in variant_styles.items()}\n",
    "        )\n",
    "        ax2.set_title('Total Events Reached Distribution by Variant')\n",
    "        ax2.set_xlabel('Variant')\n",
    "        ax2.set_ylabel('Total Events Reached')\n",
    "        ax2.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax2.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # 3. Normalized Performance Plot\n",
    "        ax3 = fig.add_subplot(gs[1, 0])\n",
    "        completed_runs = self.runs_df[self.runs_df['status'] == 'Completed']\n",
    "        \n",
    "        # Calculate normalized metrics per seed\n",
    "        normalized_metrics = []\n",
    "        for seed in completed_runs['seed'].unique():\n",
    "            seed_data = completed_runs[completed_runs['seed'] == seed]\n",
    "            if not seed_data.empty:\n",
    "                # Normalize runtime and cost by the minimum value for that seed\n",
    "                min_runtime = seed_data['runtime'].min()\n",
    "                min_cost = seed_data['total_cost'].min()\n",
    "                \n",
    "                for _, row in seed_data.iterrows():\n",
    "                    normalized_metrics.append({\n",
    "                        'variant': row['variant'],\n",
    "                        'seed': seed,\n",
    "                        'normalized_runtime': row['runtime'] / min_runtime,\n",
    "                        'normalized_cost': row['total_cost'] / min_cost\n",
    "                    })\n",
    "        \n",
    "        norm_df = pd.DataFrame(normalized_metrics)\n",
    "        \n",
    "        # Plot normalized metrics\n",
    "        for variant in variants:\n",
    "            variant_data = norm_df[norm_df['variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                ax3.scatter(\n",
    "                    variant_data['normalized_runtime'],\n",
    "                    variant_data['normalized_cost'],\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    label=self._format_variant_name(variant),\n",
    "                    alpha=0.7,\n",
    "                    s=100\n",
    "                )\n",
    "        \n",
    "        ax3.set_title('Normalized Performance (Relative to Best in Each Seed)')\n",
    "        ax3.set_xlabel('Normalized Runtime (1.0 = Best)')\n",
    "        ax3.set_ylabel('Normalized Cost (1.0 = Best)')\n",
    "        ax3.plot([1, ax3.get_xlim()[1]], [1, 1], 'k--', alpha=0.3)  # Horizontal reference\n",
    "        ax3.plot([1, 1], [1, ax3.get_ylim()[1]], 'k--', alpha=0.3)  # Vertical reference\n",
    "        ax3.legend(bbox_to_anchor=(1.02, 1))\n",
    "\n",
    "        # 4. Relative Performance Heatmap with improved explanation\n",
    "        ax4 = fig.add_subplot(gs[1, 1])\n",
    "        completed_variants = completed_runs['variant'].unique()\n",
    "        seed_performance = completed_runs.pivot_table(\n",
    "            values=['runtime', 'total_cost'],\n",
    "            index='seed',\n",
    "            columns='variant',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        \n",
    "        # Normalize each metric within seeds\n",
    "        relative_cost = seed_performance['total_cost'].div(seed_performance['total_cost'].mean(axis=1), axis=0)\n",
    "        relative_runtime = seed_performance['runtime'].div(seed_performance['runtime'].mean(axis=1), axis=0)\n",
    "        \n",
    "        # Combine metrics (you could weight them differently if desired)\n",
    "        relative_performance = (relative_cost + relative_runtime) / 2\n",
    "        \n",
    "        relative_performance = relative_performance[variants]  # Reorder columns\n",
    "        \n",
    "        sns.heatmap(\n",
    "            relative_performance,\n",
    "            ax=ax4,\n",
    "            cmap='RdYlBu_r',\n",
    "            center=1,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Relative Performance\\n(Lower is Better)'}\n",
    "        )\n",
    "        ax4.set_title('Relative Performance by Seed\\n(Combined Runtime and Cost, Normalized per Seed)')\n",
    "        ax4.set_xlabel('Variant')\n",
    "        ax4.set_ylabel('Seed')\n",
    "        ax4.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax4.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # 5. Stability Score Plot\n",
    "        ax5 = fig.add_subplot(gs[2, 0])\n",
    "        \n",
    "        # Calculate stability scores\n",
    "        stability_scores = {}\n",
    "        for variant in completed_variants:\n",
    "            variant_data = completed_runs[completed_runs['variant'] == variant]\n",
    "            \n",
    "            # Calculate coefficient of variation for key metrics\n",
    "            runtime_cv = (variant_data['runtime'].std() / variant_data['runtime'].mean()) * 100\n",
    "            cost_cv = (variant_data['total_cost'].std() / variant_data['total_cost'].mean()) * 100\n",
    "            events_cv = (variant_data['events_reached'].std() / variant_data['events_reached'].mean()) * 100\n",
    "            \n",
    "            # Combined stability score (lower is better)\n",
    "            stability_scores[variant] = {\n",
    "                'Runtime CV': runtime_cv,\n",
    "                'Cost CV': cost_cv,\n",
    "                'Events CV': events_cv\n",
    "            }\n",
    "        \n",
    "        stability_df = pd.DataFrame(stability_scores).T\n",
    "        stability_df.plot(\n",
    "            kind='bar',\n",
    "            ax=ax5,\n",
    "            width=0.8\n",
    "        )\n",
    "        ax5.set_title('Stability Analysis (Lower CV = More Stable)')\n",
    "        ax5.set_xlabel('Variant')\n",
    "        ax5.set_ylabel('Coefficient of Variation (%)')\n",
    "        ax5.set_xticklabels(\n",
    "            [self._format_variant_name(x) for x in stability_df.index],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "        ax5.legend(bbox_to_anchor=(1.02, 1))\n",
    "\n",
    "        # 6. Success Rate vs Performance Plot\n",
    "        ax6 = fig.add_subplot(gs[2, 1])\n",
    "        \n",
    "        # Calculate success rate and average normalized performance\n",
    "        performance_metrics = []\n",
    "        for variant in variants:\n",
    "            variant_runs = self.runs_df[self.runs_df['variant'] == variant]\n",
    "            success_rate = (variant_runs['status'] == 'Completed').mean() * 100\n",
    "            \n",
    "            variant_norm = norm_df[norm_df['variant'] == variant]\n",
    "            if not variant_norm.empty:\n",
    "                avg_norm_performance = (variant_norm['normalized_runtime'] + \n",
    "                                     variant_norm['normalized_cost']).mean() / 2\n",
    "            else:\n",
    "                avg_norm_performance = np.nan\n",
    "                \n",
    "            performance_metrics.append({\n",
    "                'variant': variant,\n",
    "                'success_rate': success_rate,\n",
    "                'avg_normalized_performance': avg_norm_performance\n",
    "            })\n",
    "        \n",
    "        perf_df = pd.DataFrame(performance_metrics)\n",
    "        \n",
    "        for variant in variants:\n",
    "            variant_data = perf_df[perf_df['variant'] == variant]\n",
    "            if not variant_data.empty and not np.isnan(variant_data['avg_normalized_performance'].iloc[0]):\n",
    "                style = variant_styles[variant]\n",
    "                ax6.scatter(\n",
    "                    variant_data['success_rate'],\n",
    "                    variant_data['avg_normalized_performance'],\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    s=200,\n",
    "                    label=self._format_variant_name(variant)\n",
    "                )\n",
    "                \n",
    "                # Add variant labels\n",
    "                ax6.annotate(\n",
    "                    self._format_variant_name(variant),\n",
    "                    (variant_data['success_rate'].iloc[0],\n",
    "                     variant_data['avg_normalized_performance'].iloc[0]),\n",
    "                    xytext=(5, 5),\n",
    "                    textcoords='offset points'\n",
    "                )\n",
    "        \n",
    "        ax6.set_title('Success Rate vs Average Performance')\n",
    "        ax6.set_xlabel('Success Rate (%)')\n",
    "        ax6.set_ylabel('Avg Normalized Performance\\n(Lower is Better)')\n",
    "        ax6.legend(bbox_to_anchor=(1.02, 1))\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path / 'robustness_analysis.png', dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_enhanced_robustness_analysis(self, save_path: Path = None):\n",
    "        \"\"\"Create enhanced robustness analysis visualizations with separate metric heatmaps\"\"\"\n",
    "        # Set up the figure\n",
    "        fig = plt.figure(figsize=(25, 30))\n",
    "        gs = plt.GridSpec(4, 2, figure=fig, hspace=0.4, wspace=0.3)\n",
    "        \n",
    "        # Get variants in original order from config\n",
    "        variants = [config['variant'] for config in self.raw_data['configs']]\n",
    "        \n",
    "        # 1. Runtime Heatmap\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        completed_runs = self.runs_df[self.runs_df['status'] == 'Completed']\n",
    "        runtime_pivot = completed_runs.pivot_table(\n",
    "            values='runtime',\n",
    "            index='seed',\n",
    "            columns='variant',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        # Normalize runtime within seeds\n",
    "        runtime_relative = runtime_pivot.div(runtime_pivot.mean(axis=1), axis=0)\n",
    "        runtime_relative = runtime_relative[variants]  # Reorder columns\n",
    "        \n",
    "        sns.heatmap(\n",
    "            runtime_relative,\n",
    "            ax=ax1,\n",
    "            cmap='RdYlBu_r',\n",
    "            center=1,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Relative Runtime\\n(Lower is Better)'}\n",
    "        )\n",
    "        ax1.set_title('Relative Runtime by Seed')\n",
    "        ax1.set_xlabel('Variant')\n",
    "        ax1.set_ylabel('Seed')\n",
    "        ax1.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax1.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # 2. Cost Heatmap\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        cost_pivot = completed_runs.pivot_table(\n",
    "            values='total_cost',\n",
    "            index='seed',\n",
    "            columns='variant',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        cost_relative = cost_pivot.div(cost_pivot.mean(axis=1), axis=0)\n",
    "        cost_relative = cost_relative[variants]\n",
    "        \n",
    "        sns.heatmap(\n",
    "            cost_relative,\n",
    "            ax=ax2,\n",
    "            cmap='RdYlBu_r',\n",
    "            center=1,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Relative Cost\\n(Lower is Better)'}\n",
    "        )\n",
    "        ax2.set_title('Relative Cost by Seed')\n",
    "        ax2.set_xlabel('Variant')\n",
    "        ax2.set_ylabel('Seed')\n",
    "        ax2.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax2.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # 3. Average Warehouse Utilization Heatmap (Absolute Values, Completed Runs Only)\n",
    "        ax3 = fig.add_subplot(gs[1, 0])\n",
    "        \n",
    "        # Get successful runs\n",
    "        completed_runs = self.runs_df[self.runs_df['status'] == 'Completed']\n",
    "        completed_pairs = set(zip(completed_runs['seed'], completed_runs['variant']))\n",
    "        \n",
    "        # Filter snapshots to only include data from completed runs\n",
    "        completed_snapshots = self.snapshots_df[\n",
    "            self.snapshots_df.apply(lambda row: (row['seed'], row['variant']) in completed_pairs, axis=1)\n",
    "        ]\n",
    "        \n",
    "        # Calculate average warehouse utilization for completed runs\n",
    "        util_data = completed_snapshots.groupby(['seed', 'variant'])['warehouse_utilization'].mean().reset_index()\n",
    "        util_pivot = util_data.pivot(index='seed', columns='variant', values='warehouse_utilization')\n",
    "        util_pivot = util_pivot[variants]  # Reorder columns\n",
    "        \n",
    "        # Use YlOrRd colormap for utilization (yellow=low, red=high)\n",
    "        sns.heatmap(\n",
    "            util_pivot * 100,  # Convert to percentage\n",
    "            ax=ax3,\n",
    "            cmap='YlOrRd',\n",
    "            annot=True,\n",
    "            fmt='.1f',\n",
    "            cbar_kws={'label': 'Warehouse Utilization (%)'}\n",
    "        )\n",
    "        ax3.set_title('Average Warehouse Utilization by Seed (%)')\n",
    "        ax3.set_xlabel('Variant')\n",
    "        ax3.set_ylabel('Seed')\n",
    "        ax3.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax3.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # 4. Events Reached Heatmap\n",
    "        ax4 = fig.add_subplot(gs[1, 1])\n",
    "        events_pivot = self.runs_df.pivot_table(\n",
    "            values='events_reached',\n",
    "            index='seed',\n",
    "            columns='variant',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        events_relative = events_pivot.div(events_pivot.mean(axis=1), axis=0)\n",
    "        events_relative = events_relative[variants]\n",
    "        \n",
    "        sns.heatmap(\n",
    "            events_relative,\n",
    "            ax=ax4,\n",
    "            cmap='RdYlBu_r',\n",
    "            center=1,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Relative Events Reached\\n(Higher is Better)'}\n",
    "        )\n",
    "        ax4.set_title('Relative Events Reached by Seed')\n",
    "        ax4.set_xlabel('Variant')\n",
    "        ax4.set_ylabel('Seed')\n",
    "        ax4.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax4.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # 5. Time to Failure/Termination Heatmap\n",
    "        ax5 = fig.add_subplot(gs[2, 0])\n",
    "        failed_terminated = self.runs_df[self.runs_df['status'].isin(['Failed', 'Terminated'])]\n",
    "        if not failed_terminated.empty:\n",
    "            failure_pivot = failed_terminated.pivot_table(\n",
    "                values='events_reached',\n",
    "                index='seed',\n",
    "                columns='variant',\n",
    "                aggfunc='mean'\n",
    "            )\n",
    "            failure_relative = failure_pivot.div(failure_pivot.mean(axis=1), axis=0)\n",
    "            failure_relative = failure_relative[variants]\n",
    "            \n",
    "            sns.heatmap(\n",
    "                failure_relative,\n",
    "                ax=ax5,\n",
    "                cmap='RdYlBu_r',\n",
    "                center=1,\n",
    "                annot=True,\n",
    "                fmt='.2f',\n",
    "                cbar_kws={'label': 'Relative Time to Failure\\n(Higher is Better)'}\n",
    "            )\n",
    "            ax5.set_title('Relative Time to Failure/Termination by Seed')\n",
    "            ax5.set_xlabel('Variant')\n",
    "            ax5.set_ylabel('Seed')\n",
    "            ax5.set_xticklabels(\n",
    "                [self._format_variant_name(x.get_text()) for x in ax5.get_xticklabels()],\n",
    "                rotation=30,\n",
    "                ha='right'\n",
    "            )\n",
    "\n",
    "        # 6. Success Rate Plot (kept from original)\n",
    "        ax6 = fig.add_subplot(gs[2, 1])\n",
    "        success_rates = self.runs_df.groupby('variant')['status'].value_counts(normalize=True).unstack()\n",
    "        success_rates = success_rates.reindex(variants)\n",
    "        \n",
    "        status_colors = {\n",
    "            'Failed': '#e74c3c',     # Red\n",
    "            'Terminated': '#f1c40f',  # Yellow\n",
    "            'Completed': '#2ecc71'    # Green\n",
    "        }\n",
    "        status_order = ['Failed', 'Terminated', 'Completed']\n",
    "        success_rates = success_rates[status_order]\n",
    "        \n",
    "        success_rates.plot(\n",
    "            kind='bar',\n",
    "            stacked=True,\n",
    "            ax=ax6,\n",
    "            color=[status_colors[x] for x in status_order]\n",
    "        )\n",
    "        \n",
    "        # Add percentage labels on bars\n",
    "        for c in ax6.containers:\n",
    "            labels = [f'{(v*100):.0f}%' if v > 0 else '' for v in c.datavalues]\n",
    "            ax6.bar_label(c, labels=labels, label_type='center')\n",
    "            \n",
    "        ax6.set_title('Success Rate by Variant')\n",
    "        ax6.set_xlabel('Variant')\n",
    "        ax6.set_ylabel('Percentage')\n",
    "        ax6.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax6.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "        ax6.legend(title='Status', bbox_to_anchor=(1.02, 1))\n",
    "\n",
    "        # Add summary statistics table\n",
    "        ax7 = fig.add_subplot(gs[3, :])\n",
    "        ax7.axis('off')\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        summary_data = []\n",
    "        for variant in variants:\n",
    "            variant_data = self.runs_df[self.runs_df['variant'] == variant]\n",
    "            completed_data = variant_data[variant_data['status'] == 'Completed']\n",
    "            \n",
    "            summary = {\n",
    "                'Variant': self._format_variant_name(variant),\n",
    "                'Success Rate': f\"{(len(completed_data) / len(variant_data) * 100):.1f}%\",\n",
    "                'Avg Runtime': f\"{completed_data['runtime'].mean():.1f}s\" if not completed_data.empty else 'N/A',\n",
    "                'Avg Cost': f\"{completed_data['total_cost'].mean():.0f}\" if not completed_data.empty else 'N/A',\n",
    "                'Avg Events': f\"{variant_data['events_reached'].mean():.0f}\",\n",
    "                'Avg Utilization': f\"{self.snapshots_df[self.snapshots_df['variant'] == variant]['warehouse_utilization'].mean()*100:.1f}%\"\n",
    "            }\n",
    "            summary_data.append(summary)\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        table = ax7.table(\n",
    "            cellText=summary_df.values,\n",
    "            colLabels=summary_df.columns,\n",
    "            loc='center',\n",
    "            cellLoc='center'\n",
    "        )\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(9)\n",
    "        table.scale(1.2, 1.5)\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 0.95, 0.95])\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path / 'enhanced_robustness_analysis.png', \n",
    "                        dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def generate_robustness_summary(self, output_path: Path):\n",
    "        \"\"\"Generate improved robustness statistics\"\"\"\n",
    "        # Status distribution\n",
    "        status_dist = pd.crosstab(\n",
    "            self.runs_df['variant'],\n",
    "            self.runs_df['status'],\n",
    "            normalize='index'\n",
    "        ).round(3) * 100\n",
    "\n",
    "        # Performance metrics for completed runs only\n",
    "        completed_runs = self.runs_df[self.runs_df['status'] == 'Completed']\n",
    "        \n",
    "        # Calculate normalized metrics per seed\n",
    "        normalized_metrics = []\n",
    "        for seed in completed_runs['seed'].unique():\n",
    "            seed_data = completed_runs[completed_runs['seed'] == seed]\n",
    "            if not seed_data.empty:\n",
    "                min_runtime = seed_data['runtime'].min()\n",
    "                min_cost = seed_data['total_cost'].min()\n",
    "                \n",
    "                for _, row in seed_data.iterrows():\n",
    "                    normalized_metrics.append({\n",
    "                        'variant': row['variant'],\n",
    "                        'seed': seed,\n",
    "                        'normalized_runtime': row['runtime'] / min_runtime,\n",
    "                        'normalized_cost': row['total_cost'] / min_cost\n",
    "                    })\n",
    "        \n",
    "        norm_df = pd.DataFrame(normalized_metrics)\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        performance_stats = pd.DataFrame()\n",
    "        \n",
    "        # Success rate\n",
    "        success_rate = (self.runs_df['status'] == 'Completed').groupby(self.runs_df['variant']).mean() * 100\n",
    "        performance_stats['Success Rate (%)'] = success_rate\n",
    "        \n",
    "        # Average normalized performance (when completed)\n",
    "        avg_norm_performance = norm_df.groupby('variant').agg({\n",
    "            'normalized_runtime': ['mean', 'std'],\n",
    "            'normalized_cost': ['mean', 'std']\n",
    "        })\n",
    "        \n",
    "        performance_stats['Avg Normalized Runtime'] = avg_norm_performance['normalized_runtime']['mean']\n",
    "        performance_stats['Runtime Stability (CV%)'] = (\n",
    "            avg_norm_performance['normalized_runtime']['std'] / \n",
    "            avg_norm_performance['normalized_runtime']['mean'] * 100\n",
    "        )\n",
    "        \n",
    "        performance_stats['Avg Normalized Cost'] = avg_norm_performance['normalized_cost']['mean']\n",
    "        performance_stats['Cost Stability (CV%)'] = (\n",
    "            avg_norm_performance['normalized_cost']['std'] / \n",
    "            avg_norm_performance['normalized_cost']['mean'] * 100\n",
    "        )\n",
    "        \n",
    "        # Average events reached (all runs)\n",
    "        events_stats = self.runs_df.groupby('variant')['events_reached'].agg([\n",
    "            'mean', 'std', 'min', 'max'\n",
    "        ]).round(2)\n",
    "        \n",
    "        performance_stats['Avg Events Reached'] = events_stats['mean']\n",
    "        \n",
    "        # Format the index to be more readable\n",
    "        performance_stats.index = [self._format_variant_name(v) for v in performance_stats.index]\n",
    "        \n",
    "        # Save to CSV\n",
    "        performance_stats.to_csv(output_path / 'robustness_summary.csv')\n",
    "        \n",
    "        return performance_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarehouseAnalyzer:\n",
    "    def __init__(self, results_paths_by_size):\n",
    "        \"\"\"Initialize with dictionary mapping warehouse sizes to result file paths\n",
    "        \n",
    "        Args:\n",
    "            results_paths_by_size (dict): Dictionary mapping warehouse dimensions (str) to result file path\n",
    "        \"\"\"\n",
    "        self.analyzers_by_size = {}\n",
    "        # Keep original order of dimensions\n",
    "        self.dimensions = list(results_paths_by_size.keys())\n",
    "        \n",
    "        # Create BlockRelocationAnalyzer for each warehouse size (single file version)\n",
    "        for dim, paths in results_paths_by_size.items():\n",
    "            # Take first (and only) path from the list\n",
    "            self.analyzers_by_size[dim] = BlockRelocationAnalyzer(paths[0])\n",
    "            \n",
    "        # Get variants in original order from configs\n",
    "        self.variants = [config['variant'] for config in \n",
    "                        list(self.analyzers_by_size.values())[0].raw_data['configs']]\n",
    "        \n",
    "        # Set up consistent plotting style\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        # Import matplotlib ticker for log scale formatting\n",
    "        from matplotlib import ticker\n",
    "        plt.rcParams.update({\n",
    "            'font.family': 'serif',\n",
    "            'font.size': 10,\n",
    "            'figure.figsize': [20, 10],\n",
    "            'axes.titlesize': 12,\n",
    "            'axes.labelsize': 10,\n",
    "            'legend.fontsize': 9,\n",
    "            'legend.framealpha': 1.0,\n",
    "            'legend.facecolor': 'white',\n",
    "            'legend.edgecolor': 'gray'\n",
    "        })\n",
    "\n",
    "    def _format_variant_name(self, name: str) -> str:\n",
    "        \"\"\"Format variant names for better readability\"\"\"\n",
    "        words = []\n",
    "        current = \"\"\n",
    "        for char in name:\n",
    "            if char.isupper() and current:\n",
    "                words.append(current)\n",
    "                current = char\n",
    "            else:\n",
    "                current += char\n",
    "        words.append(current)\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def plot_warehouse_analysis(self, save_path: Path = None):\n",
    "        \"\"\"Create visualization comparing variant performance across warehouse sizes\"\"\"\n",
    "        fig = plt.figure(figsize=(29, 23))\n",
    "        gs = plt.GridSpec(3, 2, figure=fig, hspace=0.4, wspace=0.3)\n",
    "\n",
    "        # Set up consistent colors and markers for variants\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, len(self.variants)))\n",
    "        markers = ['o', 's', '^', 'D', 'v', 'p', '*']\n",
    "        variant_styles = {\n",
    "            variant: {\n",
    "                'color': color,\n",
    "                'marker': marker\n",
    "            }\n",
    "            for variant, color, marker in zip(self.variants, colors, markers)\n",
    "        }\n",
    "\n",
    "        # 1. Success Rate Heatmap\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        success_data = []\n",
    "        \n",
    "        for dim in self.dimensions:  # Use stored order\n",
    "            analyzer = self.analyzers_by_size[dim]\n",
    "            for variant in self.variants:  # Use original variant order\n",
    "                variant_runs = analyzer.runs_df[analyzer.runs_df['variant'] == variant]\n",
    "                success_rate = (variant_runs['status'] == 'Completed').mean() * 100\n",
    "                success_data.append({\n",
    "                    'Warehouse': dim,\n",
    "                    'Variant': variant,\n",
    "                    'Success Rate': success_rate\n",
    "                })\n",
    "        \n",
    "        success_df = pd.DataFrame(success_data)\n",
    "        success_pivot = success_df.pivot(\n",
    "            index='Warehouse',\n",
    "            columns='Variant',\n",
    "            values='Success Rate'\n",
    "        )\n",
    "        # Ensure correct column order\n",
    "        success_pivot = success_pivot[self.variants]\n",
    "        \n",
    "        sns.heatmap(\n",
    "            success_pivot,\n",
    "            ax=ax1,\n",
    "            cmap='RdYlGn',\n",
    "            annot=True,\n",
    "            fmt='.1f',\n",
    "            vmin=0,\n",
    "            vmax=100,\n",
    "            cbar_kws={'label': 'Success Rate (%)'}\n",
    "        )\n",
    "        ax1.set_title('Success Rate by Warehouse Size')\n",
    "        ax1.set_xlabel('Variant')\n",
    "        ax1.set_ylabel('Warehouse Dimensions')\n",
    "        ax1.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax1.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # 2. Runtime Analysis\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        runtime_data = []\n",
    "        \n",
    "        for dim in self.dimensions:\n",
    "            analyzer = self.analyzers_by_size[dim]\n",
    "            completed_runs = analyzer.runs_df[analyzer.runs_df['status'] == 'Completed']\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                variant_runs = completed_runs[completed_runs['variant'] == variant]\n",
    "                if not variant_runs.empty:\n",
    "                    runtime_data.append({\n",
    "                        'Warehouse': dim,\n",
    "                        'Variant': variant,\n",
    "                        'Runtime': variant_runs['runtime'].mean()\n",
    "                    })\n",
    "        \n",
    "        runtime_df = pd.DataFrame(runtime_data)\n",
    "        # Ensure warehouse dimension ordering\n",
    "        runtime_df['Warehouse'] = pd.Categorical(runtime_df['Warehouse'], categories=self.dimensions, ordered=True)\n",
    "        runtime_df = runtime_df.sort_values('Warehouse')\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            variant_data = runtime_df[runtime_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                # Get indices for the dimensions present in variant_data\n",
    "                x_indices = [self.dimensions.index(dim) for dim in variant_data['Warehouse']]\n",
    "                ax2.plot(\n",
    "                    x_indices,\n",
    "                    variant_data['Runtime'],\n",
    "                    label=self._format_variant_name(variant),\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markersize=10,\n",
    "                    linewidth=2\n",
    "                )\n",
    "                \n",
    "        ax2.set_yscale('log')  # Set log scale for runtime\n",
    "        ax2.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{x:.1f}s'))  # Format y-axis labels\n",
    "        ax2.grid(True, which=\"both\", ls=\"-\", alpha=0.2)  # Add grid for both major and minor ticks\n",
    "        \n",
    "        # Add minor grid lines\n",
    "        ax2.grid(True, which=\"minor\", ls=\":\", alpha=0.1)\n",
    "        \n",
    "        ax2.set_title('Average Runtime by Warehouse Size\\n(Completed Runs Only)')\n",
    "        ax2.set_xlabel('Warehouse Dimensions')\n",
    "        ax2.set_xticks(range(len(self.dimensions)))\n",
    "        ax2.set_xticklabels(self.dimensions)\n",
    "        ax2.set_ylabel('Runtime (seconds)')\n",
    "        ax2.legend(bbox_to_anchor=(1.02, 1))\n",
    "        ax2.grid(True)\n",
    "\n",
    "        # 3. Cost Analysis\n",
    "        ax3 = fig.add_subplot(gs[1, 0])\n",
    "        cost_data = []\n",
    "        \n",
    "        for dim in self.dimensions:\n",
    "            analyzer = self.analyzers_by_size[dim]\n",
    "            completed_runs = analyzer.runs_df[analyzer.runs_df['status'] == 'Completed']\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                variant_runs = completed_runs[completed_runs['variant'] == variant]\n",
    "                if not variant_runs.empty:\n",
    "                    cost_data.append({\n",
    "                        'Warehouse': dim,\n",
    "                        'Variant': variant,\n",
    "                        'Cost': variant_runs['total_cost'].mean()\n",
    "                    })\n",
    "        \n",
    "        cost_df = pd.DataFrame(cost_data)\n",
    "        # Ensure warehouse dimension ordering\n",
    "        cost_df['Warehouse'] = pd.Categorical(cost_df['Warehouse'], categories=self.dimensions, ordered=True)\n",
    "        cost_df = cost_df.sort_values('Warehouse')\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            variant_data = cost_df[cost_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                # Get indices for the dimensions present in variant_data\n",
    "                x_indices = [self.dimensions.index(dim) for dim in variant_data['Warehouse']]\n",
    "                ax3.plot(\n",
    "                    x_indices,\n",
    "                    variant_data['Cost'],\n",
    "                    label=self._format_variant_name(variant),\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markersize=10,\n",
    "                    linewidth=2\n",
    "                )\n",
    "        \n",
    "        ax3.set_title('Average Cost by Warehouse Size\\n(Completed Runs Only)')\n",
    "        ax3.set_xlabel('Warehouse Dimensions')\n",
    "        ax3.set_xticks(range(len(self.dimensions)))\n",
    "        ax3.set_xticklabels(self.dimensions)\n",
    "        ax3.set_ylabel('Total Cost')\n",
    "        ax3.legend(bbox_to_anchor=(1.02, 1))\n",
    "        ax3.grid(True)\n",
    "\n",
    "        # 4. Warehouse Utilization\n",
    "        ax4 = fig.add_subplot(gs[1, 1])\n",
    "        utilization_data = []\n",
    "        \n",
    "        for dim in self.dimensions:\n",
    "            analyzer = self.analyzers_by_size[dim]\n",
    "            # Only consider snapshots from completed runs\n",
    "            completed_runs = analyzer.runs_df[analyzer.runs_df['status'] == 'Completed']\n",
    "            completed_pairs = set(zip(completed_runs['seed'], completed_runs['variant']))\n",
    "            \n",
    "            completed_snapshots = analyzer.snapshots_df[\n",
    "                analyzer.snapshots_df.apply(lambda row: \n",
    "                    (row['seed'], row['variant']) in completed_pairs, axis=1)\n",
    "            ]\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                variant_snapshots = completed_snapshots[\n",
    "                    completed_snapshots['variant'] == variant]\n",
    "                if not variant_snapshots.empty:\n",
    "                    utilization_data.append({\n",
    "                        'Warehouse': dim,\n",
    "                        'Variant': variant,\n",
    "                        'Utilization': variant_snapshots['warehouse_utilization'].mean() * 100\n",
    "                    })\n",
    "        \n",
    "        util_df = pd.DataFrame(utilization_data)\n",
    "        # Ensure warehouse dimension ordering\n",
    "        util_df['Warehouse'] = pd.Categorical(util_df['Warehouse'], categories=self.dimensions, ordered=True)\n",
    "        util_df = util_df.sort_values('Warehouse')\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            variant_data = util_df[util_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                # Get indices for the dimensions present in variant_data\n",
    "                x_indices = [self.dimensions.index(dim) for dim in variant_data['Warehouse']]\n",
    "                ax4.plot(\n",
    "                    x_indices,\n",
    "                    variant_data['Utilization'],\n",
    "                    label=self._format_variant_name(variant),\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markersize=10,\n",
    "                    linewidth=2\n",
    "                )\n",
    "        \n",
    "        ax4.set_title('Average Warehouse Utilization\\n(Completed Runs Only)')\n",
    "        ax4.set_xlabel('Warehouse Dimensions')\n",
    "        ax4.set_xticks(range(len(self.dimensions)))\n",
    "        ax4.set_xticklabels(self.dimensions)\n",
    "        ax4.set_ylabel('Utilization (%)')\n",
    "        ax4.legend(bbox_to_anchor=(1.02, 1))\n",
    "        ax4.grid(True)\n",
    "\n",
    "        # 5. Events Reached Analysis\n",
    "        ax5 = fig.add_subplot(gs[2, 0])\n",
    "        events_data = []\n",
    "        \n",
    "        for dim in self.dimensions:\n",
    "            analyzer = self.analyzers_by_size[dim]\n",
    "            for variant in self.variants:\n",
    "                variant_runs = analyzer.runs_df[analyzer.runs_df['variant'] == variant]\n",
    "                events_data.append({\n",
    "                    'Warehouse': dim,\n",
    "                    'Variant': variant,\n",
    "                    'Events': variant_runs['events_reached_percentage'].mean()\n",
    "                })\n",
    "        \n",
    "        events_df = pd.DataFrame(events_data)\n",
    "        # Ensure warehouse dimension ordering\n",
    "        events_df['Warehouse'] = pd.Categorical(events_df['Warehouse'], categories=self.dimensions, ordered=True)\n",
    "        events_df = events_df.sort_values('Warehouse')\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            variant_data = events_df[events_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                # Get indices for the dimensions present in variant_data\n",
    "                x_indices = [self.dimensions.index(dim) for dim in variant_data['Warehouse']]\n",
    "                ax5.plot(\n",
    "                    x_indices,\n",
    "                    variant_data['Events'],\n",
    "                    label=self._format_variant_name(variant),\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markersize=10,\n",
    "                    linewidth=2\n",
    "                )\n",
    "        \n",
    "        ax5.set_title('Average Events Reached (%)\\n(All Runs)')\n",
    "        ax5.set_xlabel('Warehouse Dimensions')\n",
    "        ax5.set_xticks(range(len(self.dimensions)))\n",
    "        ax5.set_xticklabels(self.dimensions)\n",
    "        ax5.set_ylabel('Events Reached (%)')\n",
    "        ax5.legend(bbox_to_anchor=(1.02, 1))\n",
    "        ax5.grid(True)\n",
    "\n",
    "        # 6. Status Distribution\n",
    "        ax6 = fig.add_subplot(gs[2, 1])\n",
    "        status_data = []\n",
    "        \n",
    "        for dim in self.dimensions:\n",
    "            analyzer = self.analyzers_by_size[dim]\n",
    "            status_dist = pd.crosstab(\n",
    "                analyzer.runs_df['variant'],\n",
    "                analyzer.runs_df['status'],\n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                if variant in status_dist.index:\n",
    "                    row = status_dist.loc[variant]\n",
    "                    status_data.append({\n",
    "                        'Warehouse': dim,\n",
    "                        'Variant': self._format_variant_name(variant),\n",
    "                        'Completed': row.get('Completed', 0),\n",
    "                        'Failed': row.get('Failed', 0),\n",
    "                        'Terminated': row.get('Terminated', 0)\n",
    "                    })\n",
    "        \n",
    "        status_df = pd.DataFrame(status_data)\n",
    "        \n",
    "        # Create the grouped bar plot\n",
    "        bar_width = 0.15\n",
    "        r = np.arange(len(self.dimensions))\n",
    "        \n",
    "        for i, variant in enumerate(self.variants):\n",
    "            variant_data = status_df[status_df['Variant'] == self._format_variant_name(variant)]\n",
    "            style = variant_styles[variant]\n",
    "            position = r + i * bar_width\n",
    "            \n",
    "            ax6.bar(position, \n",
    "                   variant_data['Completed'],\n",
    "                   bar_width,\n",
    "                   label=self._format_variant_name(variant),\n",
    "                   color=style['color'],\n",
    "                   alpha=0.7)\n",
    "        \n",
    "        ax6.set_title('Success Rate Distribution')\n",
    "        ax6.set_xlabel('Warehouse Dimensions')\n",
    "        ax6.set_ylabel('Success Rate (%)')\n",
    "        ax6.set_xticks(r + bar_width * (len(self.variants) - 1) / 2)\n",
    "        ax6.set_xticklabels(self.dimensions)\n",
    "        ax6.legend(bbox_to_anchor=(1.02, 1))\n",
    "        ax6.grid(True)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path / 'warehouse_analysis.png', \n",
    "                       dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def generate_warehouse_summary(self, output_path: Path):\n",
    "        \"\"\"Generate summary statistics for warehouse analysis\"\"\"\n",
    "        summary_data = []\n",
    "        \n",
    "        for dim in self.dimensions:\n",
    "            analyzer = self.analyzers_by_size[dim]\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                variant_runs = analyzer.runs_df[analyzer.runs_df['variant'] == variant]\n",
    "                completed_runs = variant_runs[variant_runs['status'] == 'Completed']\n",
    "                \n",
    "                summary = {\n",
    "                    'Warehouse': dim,\n",
    "                    'Variant': self._format_variant_name(variant),\n",
    "                    'Success Rate (%)': (len(completed_runs) / len(variant_runs) * 100).round(1),\n",
    "                    'Avg Runtime (s)': completed_runs['runtime'].mean().round(2) if not completed_runs.empty else None,\n",
    "                    'Avg Cost': completed_runs['total_cost'].mean().round(2) if not completed_runs.empty else None,\n",
    "                    'Avg Events Reached (%)': (variant_runs['events_reached_percentage'].mean()).round(1),\n",
    "                }\n",
    "                \n",
    "                # Add utilization if there are completed runs\n",
    "                if not completed_runs.empty:\n",
    "                    completed_pairs = set(zip(completed_runs['seed'], completed_runs['variant']))\n",
    "                    completed_snapshots = analyzer.snapshots_df[\n",
    "                        analyzer.snapshots_df.apply(lambda row: \n",
    "                            (row['seed'], row['variant']) in completed_pairs, axis=1)\n",
    "                    ]\n",
    "                    summary['Avg Utilization (%)'] = (\n",
    "                        completed_snapshots['warehouse_utilization'].mean() * 100\n",
    "                    ).round(1)\n",
    "                else:\n",
    "                    summary['Avg Utilization (%)'] = None\n",
    "                \n",
    "                summary_data.append(summary)\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(output_path / 'warehouse_summary.csv', index=False)\n",
    "        \n",
    "        return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamWidthAnalyzer:\n",
    "    def __init__(self, results_paths_by_beam: Dict[int, str]):\n",
    "        \"\"\"Initialize with dictionary mapping beam widths to result file paths\n",
    "        \n",
    "        Args:\n",
    "            results_paths_by_beam (dict): Dictionary mapping beam widths (int) to result file path\n",
    "        \"\"\"\n",
    "        self.analyzers_by_beam = {}\n",
    "        # Keep original order of beam widths\n",
    "        self.beam_widths = sorted(list(results_paths_by_beam.keys()))\n",
    "        \n",
    "        # Create BlockRelocationAnalyzer for each beam width\n",
    "        for beam_width, path in results_paths_by_beam.items():\n",
    "            self.analyzers_by_beam[beam_width] = BlockRelocationAnalyzer(path)\n",
    "            \n",
    "        # Get variants in original order from configs\n",
    "        self.variants = [config['variant'] for config in \n",
    "                        list(self.analyzers_by_beam.values())[0].raw_data['configs']]\n",
    "        \n",
    "        # Set up consistent plotting style\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "        plt.rcParams.update({\n",
    "            'font.family': 'serif',\n",
    "            'font.size': 10,\n",
    "            'figure.figsize': [20, 20],\n",
    "            'axes.titlesize': 12,\n",
    "            'axes.labelsize': 10,\n",
    "            'legend.fontsize': 9,\n",
    "            'legend.framealpha': 1.0,\n",
    "            'legend.facecolor': 'white',\n",
    "            'legend.edgecolor': 'gray'\n",
    "        })\n",
    "\n",
    "    def _format_variant_name(self, name: str) -> str:\n",
    "        \"\"\"Format variant names for better readability\"\"\"\n",
    "        words = []\n",
    "        current = \"\"\n",
    "        for char in name:\n",
    "            if char.isupper() and current:\n",
    "                words.append(current)\n",
    "                current = char\n",
    "            else:\n",
    "                current += char\n",
    "        words.append(current)\n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def plot_beam_width_analysis(self, save_path: Optional[Path] = None):\n",
    "        \"\"\"Create visualization comparing variant performance across beam widths\"\"\"\n",
    "        fig = plt.figure(figsize=(30, 22))\n",
    "        gs = plt.GridSpec(3, 2, figure=fig, hspace=0.4, wspace=0.3)\n",
    "\n",
    "        # Set up consistent colors and markers for variants\n",
    "        colors = plt.cm.Set2(np.linspace(0, 1, len(self.variants)))\n",
    "        markers = ['o', 's', '^', 'D', 'v', 'p', '*']\n",
    "        variant_styles = {\n",
    "            variant: {\n",
    "                'color': color,\n",
    "                'marker': marker\n",
    "            }\n",
    "            for variant, color, marker in zip(self.variants, colors, markers)\n",
    "        }\n",
    "\n",
    "        # 1. Runtime Analysis by Beam Width\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        runtime_data = []\n",
    "\n",
    "        for beam_width in self.beam_widths:\n",
    "            analyzer = self.analyzers_by_beam[beam_width]\n",
    "            completed_runs = analyzer.runs_df[analyzer.runs_df['status'] == 'Completed']\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                variant_runs = completed_runs[completed_runs['variant'] == variant]\n",
    "                if not variant_runs.empty:\n",
    "                    runtime_data.append({\n",
    "                        'Beam Width': beam_width,\n",
    "                        'Variant': variant,\n",
    "                        'Runtime': variant_runs['runtime'].mean()\n",
    "                    })\n",
    "\n",
    "        runtime_df = pd.DataFrame(runtime_data)\n",
    "\n",
    "        for variant in self.variants:\n",
    "            variant_data = runtime_df[runtime_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                ax1.plot(\n",
    "                    variant_data['Beam Width'],\n",
    "                    variant_data['Runtime'],\n",
    "                    label=self._format_variant_name(variant),\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markersize=10,\n",
    "                    linewidth=2\n",
    "                )\n",
    "\n",
    "        ax1.set_title('Runtime vs Beam Width\\n(Completed Runs Only)')\n",
    "        ax1.set_xlabel('Beam Width')\n",
    "        ax1.set_ylabel('Runtime (seconds)')\n",
    "        # Set x-axis to log scale (beam width)\n",
    "        ax1.set_xscale('log', base=2)\n",
    "        # Set y-axis to log scale (runtime)\n",
    "        ax1.set_yscale('log')\n",
    "        # Format the y-axis tick labels for better readability\n",
    "        ax1.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, pos: f'{y:.1f}'))\n",
    "        ax1.set_xticks(self.beam_widths)\n",
    "        ax1.set_xticklabels(self.beam_widths)\n",
    "        ax1.legend(bbox_to_anchor=(1.02, 1))\n",
    "        ax1.grid(True, which='both', linestyle='--', linewidth=0.5)  # Grid lines for both major and minor ticks\n",
    "        # 2. Cost Analysis by Beam Width\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        cost_data = []\n",
    "        \n",
    "        for beam_width in self.beam_widths:\n",
    "            analyzer = self.analyzers_by_beam[beam_width]\n",
    "            completed_runs = analyzer.runs_df[analyzer.runs_df['status'] == 'Completed']\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                variant_runs = completed_runs[completed_runs['variant'] == variant]\n",
    "                if not variant_runs.empty:\n",
    "                    cost_data.append({\n",
    "                        'Beam Width': beam_width,\n",
    "                        'Variant': variant,\n",
    "                        'Cost': variant_runs['total_cost'].mean()\n",
    "                    })\n",
    "        \n",
    "        cost_df = pd.DataFrame(cost_data)\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            variant_data = cost_df[cost_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                ax2.plot(\n",
    "                    variant_data['Beam Width'],\n",
    "                    variant_data['Cost'],\n",
    "                    label=self._format_variant_name(variant),\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markersize=10,\n",
    "                    linewidth=2\n",
    "                )\n",
    "        \n",
    "        ax2.set_title('Cost vs Beam Width\\n(Completed Runs Only)')\n",
    "        ax2.set_xlabel('Beam Width')\n",
    "        ax2.set_ylabel('Total Cost')\n",
    "        ax2.set_xscale('log', base=2)  # Log scale for beam width\n",
    "        ax2.set_xticks(self.beam_widths)\n",
    "        ax2.set_xticklabels(self.beam_widths)\n",
    "        ax2.legend(bbox_to_anchor=(1.02, 1))\n",
    "        ax2.grid(True)\n",
    "\n",
    "        # 3. Success Rate by Beam Width\n",
    "        ax3 = fig.add_subplot(gs[1, 0])\n",
    "        success_data = []\n",
    "        \n",
    "        for beam_width in self.beam_widths:\n",
    "            analyzer = self.analyzers_by_beam[beam_width]\n",
    "            for variant in self.variants:\n",
    "                variant_runs = analyzer.runs_df[analyzer.runs_df['variant'] == variant]\n",
    "                success_rate = (variant_runs['status'] == 'Completed').mean() * 100\n",
    "                success_data.append({\n",
    "                    'Beam Width': beam_width,\n",
    "                    'Variant': variant,\n",
    "                    'Success Rate': success_rate\n",
    "                })\n",
    "        \n",
    "        success_df = pd.DataFrame(success_data)\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            variant_data = success_df[success_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                ax3.plot(\n",
    "                    variant_data['Beam Width'],\n",
    "                    variant_data['Success Rate'],\n",
    "                    label=self._format_variant_name(variant),\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markersize=10,\n",
    "                    linewidth=2\n",
    "                )\n",
    "        \n",
    "        ax3.set_title('Success Rate vs Beam Width')\n",
    "        ax3.set_xlabel('Beam Width')\n",
    "        ax3.set_ylabel('Success Rate (%)')\n",
    "        ax3.set_xscale('log', base=2)  # Log scale for beam width\n",
    "        ax3.set_xticks(self.beam_widths)\n",
    "        ax3.set_xticklabels(self.beam_widths)\n",
    "        ax3.set_ylim(0, 105)  # Set y-axis limit to ensure 100% is visible\n",
    "        ax3.legend(bbox_to_anchor=(1.02, 1))\n",
    "        ax3.grid(True)\n",
    "\n",
    "        # 4. Success Rate Heatmap\n",
    "        ax4 = fig.add_subplot(gs[1, 1])\n",
    "        success_pivot = success_df.pivot(\n",
    "            index='Beam Width',\n",
    "            columns='Variant',\n",
    "            values='Success Rate'\n",
    "        )\n",
    "        # Ensure correct column order\n",
    "        success_pivot = success_pivot[self.variants]\n",
    "        \n",
    "        sns.heatmap(\n",
    "            success_pivot,\n",
    "            ax=ax4,\n",
    "            cmap='RdYlGn',\n",
    "            annot=True,\n",
    "            fmt='.1f',\n",
    "            vmin=0,\n",
    "            vmax=100,\n",
    "            cbar_kws={'label': 'Success Rate (%)'}\n",
    "        )\n",
    "        ax4.set_title('Success Rate Heatmap')\n",
    "        ax4.set_xlabel('Variant')\n",
    "        ax4.set_ylabel('Beam Width')\n",
    "        ax4.set_xticklabels(\n",
    "            [self._format_variant_name(x.get_text()) for x in ax4.get_xticklabels()],\n",
    "            rotation=30,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "        # 5. Runtime vs Cost Scatter Plot with Beam Width as color\n",
    "        ax5 = fig.add_subplot(gs[2, 0])\n",
    "        \n",
    "        runtime_cost_data = []\n",
    "        for beam_width in self.beam_widths:\n",
    "            analyzer = self.analyzers_by_beam[beam_width]\n",
    "            completed_runs = analyzer.runs_df[analyzer.runs_df['status'] == 'Completed']\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                variant_runs = completed_runs[completed_runs['variant'] == variant]\n",
    "                if not variant_runs.empty:\n",
    "                    runtime_cost_data.append({\n",
    "                        'Beam Width': beam_width,\n",
    "                        'Variant': variant,\n",
    "                        'Runtime': variant_runs['runtime'].mean(),\n",
    "                        'Cost': variant_runs['total_cost'].mean()\n",
    "                    })\n",
    "        \n",
    "        runtime_cost_df = pd.DataFrame(runtime_cost_data)\n",
    "        \n",
    "        # Create a colormap for beam widths\n",
    "        beam_cmap = plt.cm.viridis\n",
    "        beam_norm = plt.Normalize(min(self.beam_widths), max(self.beam_widths))\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            variant_data = runtime_cost_df[runtime_cost_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                \n",
    "                # Draw lines connecting points of the same variant\n",
    "\n",
    "                \n",
    "                # Plot points with beam width as color intensity\n",
    "                for _, row in variant_data.iterrows():\n",
    "                    ax5.scatter(\n",
    "                        row['Runtime'],\n",
    "                        row['Cost'],\n",
    "                        color=style['color'],\n",
    "                        marker=style['marker'],\n",
    "                        s=130,\n",
    "                        label=f\"{self._format_variant_name(variant)} (Beam: {row['Beam Width']})\" if _ == variant_data.index[0] else \"\",\n",
    "                        alpha=0.8,\n",
    "                        edgecolor='black',\n",
    "                        linewidth=1\n",
    "                    )\n",
    "                    \n",
    "                    # Add beam width text annotation\n",
    "                    ax5.annotate(\n",
    "                        str(int(row['Beam Width'])),\n",
    "                        (row['Runtime'], row['Cost']),\n",
    "                        textcoords=\"offset points\", \n",
    "                        xytext=(0,7), \n",
    "                        ha='center',\n",
    "                        fontsize=8,\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8)\n",
    "                    )\n",
    "        \n",
    "        ax5.set_title('Runtime vs Cost by Variant and Beam Width')\n",
    "        ax5.set_xlabel('Runtime (seconds)')\n",
    "        ax5.set_ylabel('Total Cost')\n",
    "        \n",
    "        # Add a legend for variants only (beam width is annotated on points)\n",
    "        handles, labels = ax5.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        ax5.legend(by_label.values(), by_label.keys(), \n",
    "                   title=\"Variants (with Beam Width labels on points)\",\n",
    "                   bbox_to_anchor=(1.02, 1))\n",
    "        ax5.grid(True)\n",
    "\n",
    "        # 6. Performance Improvement Plot (runtime and cost decrease percentage)\n",
    "        ax6 = fig.add_subplot(gs[2, 1])\n",
    "        \n",
    "        # Calculate performance improvement (compared to smallest beam width)\n",
    "        improvement_data = []\n",
    "        min_beam = min(self.beam_widths)\n",
    "        \n",
    "        # First, get baseline values for each variant with minimum beam width\n",
    "        baselines = {}\n",
    "        min_beam_analyzer = self.analyzers_by_beam[min_beam]\n",
    "        min_beam_completed = min_beam_analyzer.runs_df[min_beam_analyzer.runs_df['status'] == 'Completed']\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            variant_data = min_beam_completed[min_beam_completed['variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                baselines[variant] = {\n",
    "                    'runtime': variant_data['runtime'].mean(),\n",
    "                    'cost': variant_data['total_cost'].mean()\n",
    "                }\n",
    "        \n",
    "        # Then calculate improvements for each beam width\n",
    "        for beam_width in self.beam_widths:\n",
    "            if beam_width == min_beam:\n",
    "                continue  # Skip baseline\n",
    "                \n",
    "            analyzer = self.analyzers_by_beam[beam_width]\n",
    "            completed_runs = analyzer.runs_df[analyzer.runs_df['status'] == 'Completed']\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                if variant not in baselines:\n",
    "                    continue  # Skip if no baseline\n",
    "                    \n",
    "                variant_runs = completed_runs[completed_runs['variant'] == variant]\n",
    "                if not variant_runs.empty:\n",
    "                    runtime = variant_runs['runtime'].mean()\n",
    "                    cost = variant_runs['total_cost'].mean()\n",
    "                    \n",
    "                    runtime_improvement = (baselines[variant]['runtime'] - runtime) / baselines[variant]['runtime'] * 100\n",
    "                    cost_improvement = (baselines[variant]['cost'] - cost) / baselines[variant]['cost'] * 100\n",
    "                    \n",
    "                    improvement_data.append({\n",
    "                        'Beam Width': beam_width,\n",
    "                        'Variant': variant,\n",
    "                        'Runtime Improvement (%)': runtime_improvement,\n",
    "                        'Cost Improvement (%)': cost_improvement\n",
    "                    })\n",
    "        \n",
    "        improvement_df = pd.DataFrame(improvement_data)\n",
    "        \n",
    "        # Plot runtime improvement\n",
    "        for variant in self.variants:\n",
    "            variant_data = improvement_df[improvement_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                style = variant_styles[variant]\n",
    "                ax6.plot(\n",
    "                    variant_data['Beam Width'],\n",
    "                    variant_data['Runtime Improvement (%)'],\n",
    "                    label=f\"{self._format_variant_name(variant)} - Runtime\",\n",
    "                    color=style['color'],\n",
    "                    marker=style['marker'],\n",
    "                    markersize=8,\n",
    "                    linewidth=2,\n",
    "                    linestyle='-'\n",
    "                )\n",
    "                \n",
    "                # Plot cost improvement with dashed line\n",
    "                ax6.plot(\n",
    "                    variant_data['Beam Width'],\n",
    "                    variant_data['Cost Improvement (%)'],\n",
    "                    label=f\"{self._format_variant_name(variant)} - Cost\",\n",
    "                    color=style['color'],\n",
    "                    marker='x',\n",
    "                    markersize=8,\n",
    "                    linewidth=2,\n",
    "                    linestyle='--'\n",
    "                )\n",
    "        \n",
    "        ax6.set_title(f'Performance Improvement vs Beam Width\\n(Compared to Beam={min_beam})')\n",
    "        ax6.set_xlabel('Beam Width')\n",
    "        ax6.set_ylabel('Improvement (%)')\n",
    "        ax6.set_xscale('log', base=2)  # Log scale for beam width\n",
    "        ax6.set_xticks(self.beam_widths[1:])  # Skip first beam width as it's the baseline\n",
    "        ax6.set_xticklabels(self.beam_widths[1:])\n",
    "        ax6.axhline(y=0, color='k', linestyle='-', alpha=0.3)  # Add horizontal line at y=0\n",
    "        ax6.legend(bbox_to_anchor=(1.02, 1), fontsize=8)\n",
    "        ax6.grid(True)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path / 'beam_width_analysis.png', \n",
    "                       dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def generate_beam_width_summary(self, output_path: Path):\n",
    "        \"\"\"Generate summary statistics for beam width analysis\"\"\"\n",
    "        summary_data = []\n",
    "        \n",
    "        for beam_width in self.beam_widths:\n",
    "            analyzer = self.analyzers_by_beam[beam_width]\n",
    "            \n",
    "            for variant in self.variants:\n",
    "                variant_runs = analyzer.runs_df[analyzer.runs_df['variant'] == variant]\n",
    "                completed_runs = variant_runs[variant_runs['status'] == 'Completed']\n",
    "                \n",
    "                summary = {\n",
    "                    'Beam Width': beam_width,\n",
    "                    'Variant': self._format_variant_name(variant),\n",
    "                    'Success Rate (%)': (len(completed_runs) / len(variant_runs) * 100).round(1),\n",
    "                    'Avg Runtime (s)': completed_runs['runtime'].mean().round(2) if not completed_runs.empty else None,\n",
    "                    'Avg Cost': completed_runs['total_cost'].mean().round(2) if not completed_runs.empty else None,\n",
    "                    'Avg Events Reached (%)': (variant_runs['events_reached_percentage'].mean()).round(1),\n",
    "                }\n",
    "                \n",
    "                # Add warehouse utilization\n",
    "                if not completed_runs.empty:\n",
    "                    completed_pairs = set(zip(completed_runs['seed'], completed_runs['variant']))\n",
    "                    completed_snapshots = analyzer.snapshots_df[\n",
    "                        analyzer.snapshots_df.apply(lambda row: \n",
    "                            (row['seed'], row['variant']) in completed_pairs, axis=1)\n",
    "                    ]\n",
    "                    summary['Avg Utilization (%)'] = (\n",
    "                        completed_snapshots['warehouse_utilization'].mean() * 100\n",
    "                    ).round(1)\n",
    "                else:\n",
    "                    summary['Avg Utilization (%)'] = None\n",
    "                \n",
    "                summary_data.append(summary)\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(output_path / 'beam_width_summary.csv', index=False)\n",
    "        \n",
    "        return summary_df\n",
    "\n",
    "    def compute_optimal_beam_width(self, runtime_weight=0.5, cost_weight=0.5):\n",
    "        \"\"\"Compute the optimal beam width for each variant based on weighted runtime and cost\n",
    "        \n",
    "        Args:\n",
    "            runtime_weight: Weight for runtime in the optimization (default: 0.5)\n",
    "            cost_weight: Weight for cost in the optimization (default: 0.5)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with optimal beam width for each variant\n",
    "        \"\"\"\n",
    "        # Normalize runtime and cost across all beam widths for each variant\n",
    "        normalized_metrics = []\n",
    "        \n",
    "        for variant in self.variants:\n",
    "            # Extract runtime and cost for all beam widths\n",
    "            variant_metrics = []\n",
    "            for beam_width in self.beam_widths:\n",
    "                analyzer = self.analyzers_by_beam[beam_width]\n",
    "                completed_runs = analyzer.runs_df[\n",
    "                    (analyzer.runs_df['variant'] == variant) &\n",
    "                    (analyzer.runs_df['status'] == 'Completed')\n",
    "                ]\n",
    "                \n",
    "                if not completed_runs.empty:\n",
    "                    variant_metrics.append({\n",
    "                        'Beam Width': beam_width,\n",
    "                        'Runtime': completed_runs['runtime'].mean(),\n",
    "                        'Cost': completed_runs['total_cost'].mean(),\n",
    "                        'Success Rate': (len(completed_runs) / len(analyzer.runs_df[analyzer.runs_df['variant'] == variant])) * 100\n",
    "                    })\n",
    "            \n",
    "            if not variant_metrics:\n",
    "                continue\n",
    "                \n",
    "            # Convert to DataFrame for easier processing\n",
    "            metrics_df = pd.DataFrame(variant_metrics)\n",
    "            \n",
    "            # Skip if we don't have at least two beam widths\n",
    "            if len(metrics_df) <= 1:\n",
    "                continue\n",
    "                \n",
    "            # Min-max normalization of runtime and cost\n",
    "            min_runtime = metrics_df['Runtime'].min()\n",
    "            max_runtime = metrics_df['Runtime'].max()\n",
    "            min_cost = metrics_df['Cost'].min()\n",
    "            max_cost = metrics_df['Cost'].max()\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            runtime_range = max_runtime - min_runtime\n",
    "            cost_range = max_cost - min_cost\n",
    "            \n",
    "            # Calculate normalized values (0 is best, 1 is worst)\n",
    "            for _, row in metrics_df.iterrows():\n",
    "                normalized_runtime = 0 if runtime_range == 0 else (row['Runtime'] - min_runtime) / runtime_range\n",
    "                normalized_cost = 0 if cost_range == 0 else (row['Cost'] - min_cost) / cost_range\n",
    "                \n",
    "                # Calculate weighted score (lower is better)\n",
    "                weighted_score = (runtime_weight * normalized_runtime) + (cost_weight * normalized_cost)\n",
    "                \n",
    "                normalized_metrics.append({\n",
    "                    'Variant': variant,\n",
    "                    'Beam Width': row['Beam Width'],\n",
    "                    'Normalized Runtime': normalized_runtime,\n",
    "                    'Normalized Cost': normalized_cost,\n",
    "                    'Weighted Score': weighted_score,\n",
    "                    'Success Rate': row['Success Rate'],\n",
    "                    'Runtime': row['Runtime'],\n",
    "                    'Cost': row['Cost']\n",
    "                })\n",
    "        \n",
    "        norm_df = pd.DataFrame(normalized_metrics)\n",
    "        \n",
    "        # Find optimal beam width for each variant (minimum weighted score)\n",
    "        optimal_beam = []\n",
    "        for variant in self.variants:\n",
    "            variant_data = norm_df[norm_df['Variant'] == variant]\n",
    "            if not variant_data.empty:\n",
    "                # Find the optimal beam width with at least 95% success rate\n",
    "                reliable_beams = variant_data[variant_data['Success Rate'] >= 95]\n",
    "                \n",
    "                if not reliable_beams.empty:\n",
    "                    optimal = reliable_beams.loc[reliable_beams['Weighted Score'].idxmin()]\n",
    "                else:\n",
    "                    # If no beam has 95% success, just find the minimum score\n",
    "                    optimal = variant_data.loc[variant_data['Weighted Score'].idxmin()]\n",
    "                \n",
    "                optimal_beam.append({\n",
    "                    'Variant': self._format_variant_name(variant),\n",
    "                    'Optimal Beam Width': optimal['Beam Width'],\n",
    "                    'Success Rate (%)': optimal['Success Rate'],\n",
    "                    'Runtime (s)': optimal['Runtime'],\n",
    "                    'Cost': optimal['Cost'],\n",
    "                    'Score': optimal['Weighted Score']\n",
    "                })\n",
    "        \n",
    "        optimal_df = pd.DataFrame(optimal_beam)\n",
    "        return optimal_df\n",
    "\n",
    "\n",
    "results_by_beam = {\n",
    "    2: \"results/beam_width_2_results.json\",\n",
    "    5: \"results/beam_width_5_results.json\", \n",
    "    10: \"results/beam_width_10_results.json\",\n",
    "    50: \"results/beam_width_50_results.json\"\n",
    "}\n",
    "\n",
    "analyzer = BeamWidthAnalyzer(results_by_beam)\n",
    "\n",
    "# Generate visualizations\n",
    "analyzer.plot_beam_width_analysis(save_path=Path(\"output\"))\n",
    "\n",
    "# Generate summary statistics\n",
    "analyzer.generate_beam_width_summary(output_path=Path(\"output\"))\n",
    "\n",
    "# Find optimal beam width\n",
    "optimal_beam = analyzer.compute_optimal_beam_width(runtime_weight=0.3, cost_weight=0.7)\n",
    "print(optimal_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create dictionary mapping warehouse dimensions to result files\\nresults_by_size = {\\n    \"6x3x3\": [\"results/warehouse_6x3x3.json\"],\\n    \"7x3x3\": [\"results/warehouse_7x3x3.json\"],\\n    \"7x4x3\": [\"results/warehouse_7x4x3.json\"],\\n    \"7x4x4\": [\"results/warehouse_7x5x4.json\"],\\n}\\n\\nanalyzer = WarehouseAnalyzer(results_by_size)\\n\\n# Generate visualizations\\nanalyzer.plot_warehouse_analysis(save_path=Path(\"output\"))\\n\\n# Generate summary statistics\\nsummary = analyzer.generate_warehouse_summary(output_path=Path(\"output\"))\\n\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate_visualizations(\"results/standard_results.json\")\n",
    "\n",
    "# Beam width analysis\n",
    "'''\n",
    "analyze_beam_width(\n",
    "    \"results/beam_width_{}_results.json\",\n",
    "    beam_widths=[2, 4, 8, 16]\n",
    ")\n",
    "\n",
    "# Warehouse scaling analysis\n",
    "analyze_warehouse_scaling({\n",
    "    \"5x6x3\": \"results/warehouse_5x6x3.json\",\n",
    "    \"6x8x3\": \"results/warehouse_6x8x3.json\",\n",
    "    \"8x10x3\": \"results/warehouse_8x10x3.json\"\n",
    "})\n",
    "\n",
    "# Robustness analysis with multiple seeds\n",
    "analyze_robustness(\n",
    "    \"results/seed_{}_results.json\",\n",
    "    seeds=[1337, 1338, 1339, 1340, 1341]\n",
    ")\n",
    "'''\n",
    "\n",
    "'''\n",
    "#robustness\n",
    "seeds = [1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346]  # Add your seeds here\n",
    "base_path = './results/seed_{}_results.json'  # Update this path pattern\n",
    "\n",
    "# Create list of file paths\n",
    "result_files = [base_path.format(seed) for seed in seeds]\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('robustness_analysis_output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Initialize analyzer and generate visualizations\n",
    "analyzer = RobustnessAnalyzer(result_files)\n",
    "analyzer.plot_enhanced_robustness_analysis(save_path=output_dir)\n",
    "analyzer.generate_robustness_summary(output_dir)\n",
    "'''\n",
    "'''\n",
    "# Create dictionary mapping warehouse dimensions to result files\n",
    "results_by_size = {\n",
    "    \"6x3x3\": [\"results/warehouse_6x3x3.json\"],\n",
    "    \"7x3x3\": [\"results/warehouse_7x3x3.json\"],\n",
    "    \"7x4x3\": [\"results/warehouse_7x4x3.json\"],\n",
    "    \"7x4x4\": [\"results/warehouse_7x5x4.json\"],\n",
    "}\n",
    "\n",
    "analyzer = WarehouseAnalyzer(results_by_size)\n",
    "\n",
    "# Generate visualizations\n",
    "analyzer.plot_warehouse_analysis(save_path=Path(\"output\"))\n",
    "\n",
    "# Generate summary statistics\n",
    "summary = analyzer.generate_warehouse_summary(output_path=Path(\"output\"))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
